# 健康检查机制深度解析

> 从问题出发，理解负载均衡中健康检查的设计原理与实践

---

## 目录

- [1. 为什么需要健康检查？](#1-为什么需要健康检查)
- [2. 被动健康检查（Passive Health Checks）](#2-被动健康检查passive-health-checks)
- [3. 主动健康检查（Active Health Checks）](#3-主动健康检查active-health-checks)
- [4. 对比分析：主动 vs 被动](#4-对比分析主动-vs-被动)
- [5. 组合策略设计](#5-组合策略设计)
- [6. 实践：Go 实现健康检查](#6-实践go-实现健康检查)
- [7. 生产环境最佳实践](#7-生产环境最佳实践)

---

## 1. 为什么需要健康检查？

### 1.1 问题场景

假设你有一个负载均衡器，后面有 3 台服务器：

```
客户端 → 负载均衡器 → [Server1 ✅, Server2 ✅, Server3 ✅]
```

**场景1：服务器崩溃**
```
Server2 突然崩溃 💥
客户端 → 负载均衡器 → [Server1 ✅, Server2 ❌, Server3 ✅]
```

如果负载均衡器不知道 Server2 已经挂了，仍然会将流量分配给它：
- 33% 的请求会失败
- 用户体验糟糕（错误页面、超时）
- 系统可用性降至 66.7%

**场景2：服务器过载**
```
Server1 CPU 100%，响应缓慢 🐌
客户端 → 负载均衡器 → [Server1 ⚠️, Server2 ✅, Server3 ✅]
```

如果不检测健康状态：
- Server1 继续接收流量，导致请求超时
- 可能引发雪崩效应（其他服务器也过载）

**场景3：部署新版本**
```
Server3 正在重启 🔄（部署新代码）
客户端 → 负载均衡器 → [Server1 ✅, Server2 ✅, Server3 🔄]
```

如果不检查：
- 重启期间的请求会失败
- 服务中断

### 1.2 健康检查的目标

**核心目标**：
1. **快速检测故障** - 在秒级检测到后端服务器不可用
2. **自动隔离** - 将故障服务器从负载均衡池中移除
3. **自动恢复** - 检测到服务器恢复后，重新加入池中
4. **提高可用性** - 避免将流量发送到不健康的服务器

**关键指标**：
- **检测延迟** - 从故障发生到检测到的时间
- **误判率** - 错误地将健康服务器标记为不健康（False Positive）
- **漏判率** - 未检测到实际故障（False Negative）

---

## 2. 被动健康检查（Passive Health Checks）

### 2.1 核心原理

**定义**：通过监控实际的客户端请求结果，来判断后端服务器的健康状态。

**工作流程**：

```
客户端请求 → 负载均衡器 → 后端服务器
                ↓
           监控响应状态
                ↓
         是否失败？
          /        \
        是           否
         ↓           ↓
    累计失败次数   重置计数器
         ↓
   达到阈值？
      /    \
    是      否
     ↓       ↓
  标记不健康  继续监控
```

### 2.2 实现机制

#### 核心参数

1. **fail_timeout（时间窗口）**
   - 定义：在多长时间内统计失败次数
   - 示例：30 秒

2. **max_fails（失败阈值）**
   - 定义：在时间窗口内允许的最大失败次数
   - 示例：3 次

3. **不健康持续时间**
   - 定义：服务器被标记为不健康后，多久再尝试
   - 通常等于 `fail_timeout`

#### 配置示例（Nginx）

```nginx
upstream backend {
    server backend1.example.com;
    server backend2.example.com max_fails=3 fail_timeout=30s;
    server backend3.example.com max_fails=5 fail_timeout=60s;
}
```

**解读**：
- `backend2`: 如果 30 秒内失败 3 次，标记为不健康，30 秒后重试
- `backend3`: 如果 60 秒内失败 5 次，标记为不健康，60 秒后重试

### 2.3 什么算"失败"？

不同场景对"失败"的定义：

| 失败类型 | 说明 | 示例 |
|---------|------|------|
| **连接失败** | 无法建立 TCP 连接 | 服务器关机、网络断开 |
| **超时** | 连接建立但响应超时 | 服务器挂起、数据库慢查询 |
| **HTTP 错误** | 返回 5xx 状态码 | 500 内部错误、502 网关错误 |
| **响应异常** | 返回格式错误的响应 | 非 HTTP 响应、空响应 |

### 2.4 状态转换图

```
         健康（Healthy）
              ↓
         收到请求并转发
              ↓
        监控响应结果
         /         \
      成功           失败
        ↓             ↓
   重置计数器    累计失败次数
                      ↓
                 达到阈值？
                   /    \
                 是      否
                  ↓       ↓
           不健康      继续监控
          (Unhealthy)
               ↓
       等待 fail_timeout
               ↓
          尝试恢复探测
           /        \
         成功        失败
          ↓          ↓
        健康      继续不健康
```

### 2.5 优点与缺点

#### 优点 ✅

1. **无额外开销**
   - 不需要额外的探测请求
   - 利用真实流量进行检测

2. **真实反映用户体验**
   - 检测的是实际请求的成功/失败
   - 更贴近用户感受

3. **简单实现**
   - 逻辑简单，易于实现
   - 开源负载均衡器都支持

#### 缺点 ❌

1. **检测延迟高**
   - 需要等待实际请求失败
   - 故障期间仍有流量发送到故障服务器
   - 检测时间 = 失败次数 × 请求间隔

   **示例**：
   ```
   配置: max_fails=3, fail_timeout=30s

   故障发生 → 请求1失败 → 请求2失败 → 请求3失败 → 标记不健康
   时间:    0s         5s         10s        15s

   检测延迟: 15秒（期间至少3个请求失败）
   ```

2. **低流量场景问题**
   - 如果流量很少，可能很久才能检测到故障
   - 极端情况：服务器宕机，但没有新请求，永远不会检测到

3. **无法预防性检测**
   - 只能在故障发生后检测
   - 无法提前发现问题（如内存泄漏）

---

## 3. 主动健康检查（Active Health Checks）

### 3.1 核心原理

**定义**：负载均衡器主动、定期地向后端服务器发送健康检查请求，根据响应判断服务器状态。

**工作流程**：

```
负载均衡器定时器（每 5 秒）
        ↓
  向所有后端发送探测请求
   (GET /health HTTP/1.1)
        ↓
    等待响应
     /      \
   成功      失败/超时
    ↓          ↓
 标记健康   累计失败次数
               ↓
          达到阈值？
            /    \
          是      否
           ↓       ↓
       标记不健康  继续监控
```

### 3.2 实现机制

#### 核心参数

1. **interval（检查间隔）**
   - 定义：多久发送一次健康检查
   - 推荐：3-10 秒
   - 权衡：越短检测越快，但开销越大

2. **timeout（超时时间）**
   - 定义：等待响应的最长时间
   - 推荐：1-5 秒
   - 规则：`timeout < interval`

3. **fails（失败阈值）**
   - 定义：连续失败多少次标记为不健康
   - 推荐：2-3 次
   - 目的：避免网络抖动导致误判

4. **passes（恢复阈值）**
   - 定义：连续成功多少次标记为健康
   - 推荐：2-3 次
   - 目的：确保服务器稳定后再接入流量

#### 配置示例（Nginx Plus）

```nginx
upstream backend {
    zone backend 64k;  # 共享内存区域
    server backend1.example.com;
    server backend2.example.com;
    server backend3.example.com;
}

server {
    location / {
        proxy_pass http://backend;
        health_check interval=5s   # 每 5 秒检查一次
                     timeout=3s    # 3 秒超时
                     fails=3       # 连续失败 3 次标记不健康
                     passes=2      # 连续成功 2 次标记健康
                     uri=/health;  # 健康检查端点
    }
}
```

### 3.3 健康检查端点设计

#### 简单版本：HTTP 200

```go
// 后端服务器的健康检查端点
func healthHandler(w http.ResponseWriter, r *http.Request) {
    w.WriteHeader(http.StatusOK)
    w.Write([]byte("OK"))
}

http.HandleFunc("/health", healthHandler)
```

#### 深度检查版本

```go
func healthHandler(w http.ResponseWriter, r *http.Request) {
    // 检查数据库连接
    if err := db.Ping(); err != nil {
        w.WriteHeader(http.StatusServiceUnavailable)
        w.Write([]byte("Database unreachable"))
        return
    }

    // 检查 Redis 连接
    if err := redis.Ping(); err != nil {
        w.WriteHeader(http.StatusServiceUnavailable)
        w.Write([]byte("Redis unreachable"))
        return
    }

    // 检查磁盘空间
    diskUsage := getDiskUsage()
    if diskUsage > 0.95 { // 超过 95%
        w.WriteHeader(http.StatusServiceUnavailable)
        w.Write([]byte("Disk full"))
        return
    }

    // 检查内存使用
    memUsage := getMemoryUsage()
    if memUsage > 0.90 { // 超过 90%
        w.WriteHeader(http.StatusServiceUnavailable)
        w.Write([]byte("Memory high"))
        return
    }

    w.WriteHeader(http.StatusOK)
    w.Write([]byte("OK"))
}
```

#### 自定义响应条件（Nginx Plus）

```nginx
# 定义匹配条件
match server_ok {
    status 200-399;                    # 状态码在 200-399
    header Content-Type = "text/html"; # Content-Type 头匹配
    body ~ "OK";                       # 响应体包含 "OK"
    body !~ "maintenance";             # 响应体不包含 "maintenance"
}

server {
    location / {
        proxy_pass http://backend;
        health_check match=server_ok uri=/health;
    }
}
```

### 3.4 状态转换图

```
      初始状态（未知）
           ↓
     发送第一次探测
        /        \
      成功        失败
       ↓           ↓
   健康（Healthy） 累计失败
       ↓             ↓
   定期探测       达到阈值？
    /    \         /    \
  成功    失败    是      否
   ↓       ↓       ↓       ↓
  健康  累计失败  不健康  继续累计
           ↓      (Unhealthy)
      达到阈值？       ↓
        /    \      定期探测
      是      否      /    \
       ↓       ↓    成功    失败
   不健康    健康     ↓       ↓
                  累计成功  继续不健康
                     ↓
                达到阈值？
                  /    \
                是      否
                 ↓       ↓
              健康   继续累计
```

### 3.5 优点与缺点

#### 优点 ✅

1. **检测快速**
   - 主动探测，不依赖实际流量
   - 检测延迟 = interval × fails
   - 示例：5s × 3 = 15s（最坏情况）

2. **低流量场景可用**
   - 不依赖客户端请求
   - 即使没有流量，也能检测故障

3. **预防性检测**
   - 可以检测资源使用率（内存、CPU、磁盘）
   - 在服务器崩溃前发现问题

4. **可自定义**
   - 可以检查深层依赖（数据库、缓存）
   - 可以自定义健康条件

#### 缺点 ❌

1. **额外开销**
   - 需要额外的网络请求和计算
   - 100 台服务器 × 每 5 秒 = 20 QPS 的探测流量

2. **可能与实际不符**
   - `/health` 端点可能正常，但实际业务逻辑故障
   - 示例：健康检查通过，但数据库查询超时

3. **实现复杂**
   - 需要定时器、并发控制
   - 需要额外的内存存储状态

4. **健康检查端点维护**
   - 需要开发和维护 `/health` 端点
   - 深度检查可能影响性能

---

## 4. 对比分析：主动 vs 被动

### 4.1 详细对比表

| 维度 | 被动健康检查 | 主动健康检查 |
|------|-------------|-------------|
| **检测方式** | 监控真实请求 | 发送探测请求 |
| **检测延迟** | 较慢（需等待实际请求失败） | 快速（主动探测） |
| **额外开销** | 无 | 有（探测请求） |
| **低流量场景** | ❌ 可能无法检测 | ✅ 始终能检测 |
| **准确性** | 真实反映用户体验 | 可能与实际不符 |
| **预防性** | ❌ 无法提前发现问题 | ✅ 可检测资源使用 |
| **实现复杂度** | 简单 | 中等 |
| **可用性** | 开源/商业版都支持 | 通常需要 Plus/企业版 |
| **误判风险** | 较低（真实请求） | 较高（探测请求） |

### 4.2 检测延迟对比

**场景**：服务器在时刻 T=0 崩溃

#### 被动健康检查
```
配置: max_fails=3, fail_timeout=30s
假设: 平均每 5 秒有一个请求

T=0s   : 服务器崩溃 💥
T=2s   : 第1个请求到达 → 失败 (失败计数: 1)
T=7s   : 第2个请求到达 → 失败 (失败计数: 2)
T=12s  : 第3个请求到达 → 失败 (失败计数: 3)
T=12s  : 标记为不健康 ❌

检测延迟: 12 秒
失败请求数: 3 个
```

#### 主动健康检查
```
配置: interval=5s, fails=3

T=0s   : 服务器崩溃 💥
T=1s   : 定时探测 → 失败 (失败计数: 1)
T=6s   : 定时探测 → 失败 (失败计数: 2)
T=11s  : 定时探测 → 失败 (失败计数: 3)
T=11s  : 标记为不健康 ❌

检测延迟: 11 秒
失败请求数: 0 个（客户端请求不受影响）
```

### 4.3 适用场景

| 场景 | 推荐方案 | 理由 |
|------|---------|------|
| **高流量系统** | 被动检查 | 流量本身就能快速检测故障 |
| **低流量系统** | 主动检查 | 被动检查可能检测不到 |
| **关键业务** | 主动 + 被动 | 双重保障，降低误判 |
| **成本敏感** | 被动检查 | 无额外开销 |
| **快速故障恢复要求** | 主动检查 | 检测更快 |
| **微服务架构** | 主动检查 | 需要检测服务间依赖 |
| **边缘节点** | 主动检查 | 流量不均匀，需主动探测 |

---

## 5. 组合策略设计

### 5.1 为什么要组合？

单独使用被动或主动检查都有局限性，组合使用可以：
1. **降低误判率** - 两种检查都失败才标记不健康
2. **提高检测速度** - 任意一种检查失败立即响应
3. **全面覆盖** - 既检测真实流量，又主动探测

### 5.2 组合策略1：双重确认（AND 逻辑）

**规则**：主动检查 **AND** 被动检查都失败，才标记为不健康

```
主动检查失败 ←→ 暂时标记为"可疑"
     ↓
被动检查也失败 ←→ 确认不健康，移除流量
```

**优点**：
- ✅ 降低误判率
- ✅ 避免网络抖动导致错误隔离

**缺点**：
- ❌ 检测延迟增加
- ❌ 故障期间可能有请求失败

**适用场景**：
- 对误判极度敏感
- 可以容忍短暂的故障影响

### 5.3 组合策略2：快速隔离（OR 逻辑）

**规则**：主动检查 **OR** 被动检查失败，立即标记为不健康

```
主动检查失败 ←→ 立即标记不健康
      OR
被动检查失败 ←→ 立即标记不健康
```

**优点**：
- ✅ 检测最快
- ✅ 最小化故障影响

**缺点**：
- ❌ 误判率较高

**适用场景**：
- 对可用性要求极高
- 宁可误杀，不可漏过

### 5.4 组合策略3：分级响应（推荐）

**规则**：根据健康检查结果，采取不同的响应策略

| 主动检查 | 被动检查 | 状态 | 动作 |
|---------|---------|------|------|
| ✅ 成功 | ✅ 成功 | **健康** | 正常接收流量 |
| ✅ 成功 | ❌ 失败 | **警告** | 降低权重（50%流量） |
| ❌ 失败 | ✅ 成功 | **警告** | 降低权重（50%流量） |
| ❌ 失败 | ❌ 失败 | **不健康** | 完全移除流量 |

**实现示例**（伪代码）：

```go
type HealthStatus int

const (
    Healthy   HealthStatus = 2  // 两种检查都通过
    Warning   HealthStatus = 1  // 一种检查失败
    Unhealthy HealthStatus = 0  // 两种检查都失败
)

type Server struct {
    URL            string
    ActiveHealth   bool   // 主动检查结果
    PassiveHealth  bool   // 被动检查结果
    Weight         int    // 权重
    OriginalWeight int    // 原始权重
}

func (s *Server) UpdateStatus() HealthStatus {
    if s.ActiveHealth && s.PassiveHealth {
        s.Weight = s.OriginalWeight  // 恢复完整权重
        return Healthy
    }

    if !s.ActiveHealth && !s.PassiveHealth {
        s.Weight = 0  // 移除所有流量
        return Unhealthy
    }

    s.Weight = s.OriginalWeight / 2  // 降低权重
    return Warning
}
```

**优点**：
- ✅ 平衡了速度和准确性
- ✅ 渐进式降级，避免突然断流
- ✅ 适应多种故障场景

### 5.5 实战案例：电商秒杀系统

**需求**：
- 10 台应用服务器
- 秒杀期间流量暴增（正常 1K QPS → 峰值 100K QPS）
- 可用性要求：99.99%
- 允许响应延迟：< 200ms

**健康检查策略设计**：

#### 主动健康检查配置
```nginx
health_check interval=3s     # 3 秒一次（快速检测）
             timeout=1s      # 1 秒超时
             fails=2         # 连续失败 2 次标记不健康
             passes=3        # 连续成功 3 次标记健康
             uri=/health;    # 健康端点
```

**健康端点实现**：
```go
func healthHandler(w http.ResponseWriter, r *http.Request) {
    // 1. 检查数据库连接
    if err := db.Ping(); err != nil {
        http.Error(w, "DB down", http.StatusServiceUnavailable)
        return
    }

    // 2. 检查 Redis 连接
    if err := redis.Ping(); err != nil {
        http.Error(w, "Redis down", http.StatusServiceUnavailable)
        return
    }

    // 3. 检查 CPU 使用率
    cpuUsage := getCPUUsage()
    if cpuUsage > 90 {  // 超过 90% 认为过载
        http.Error(w, "CPU high", http.StatusServiceUnavailable)
        return
    }

    // 4. 检查内存使用率
    memUsage := getMemoryUsage()
    if memUsage > 85 {  // 超过 85%
        http.Error(w, "Memory high", http.StatusServiceUnavailable)
        return
    }

    w.WriteHeader(http.StatusOK)
    w.Write([]byte("OK"))
}
```

#### 被动健康检查配置
```nginx
server backend1.example.com max_fails=3 fail_timeout=10s;
```

#### 组合策略
```
主动检查失败（CPU > 90%） → 降低权重到 50%
     ↓
继续监控被动检查
     ↓
被动检查也失败（超时） → 完全移除流量
```

**预期效果**：
- **检测延迟**：最快 3s（主动检查）
- **误判率**：< 0.1%（双重确认）
- **可用性**：99.99%+

---

## 6. 实践：Go 实现健康检查

### 6.1 项目结构

```
health-checker/
├── main.go
├── pkg/
│   ├── active/
│   │   └── checker.go      # 主动健康检查
│   ├── passive/
│   │   └── monitor.go      # 被动健康检查
│   └── strategy/
│       └── combined.go     # 组合策略
└── internal/
    └── server/
        └── server.go       # 后端服务器模型
```

### 6.2 后端服务器模型

```go
package server

import (
    "sync"
    "time"
)

type HealthStatus int

const (
    StatusUnknown HealthStatus = iota
    StatusHealthy
    StatusWarning
    StatusUnhealthy
)

type Server struct {
    URL    string
    Weight int

    // 主动健康检查状态
    ActiveHealthy      bool
    ActiveFailCount    int
    ActiveSuccessCount int

    // 被动健康检查状态
    PassiveHealthy    bool
    PassiveFailCount  int
    PassiveFailWindow time.Time

    mu sync.RWMutex
}

func (s *Server) GetStatus() HealthStatus {
    s.mu.RLock()
    defer s.mu.RUnlock()

    if s.ActiveHealthy && s.PassiveHealthy {
        return StatusHealthy
    }

    if !s.ActiveHealthy && !s.PassiveHealthy {
        return StatusUnhealthy
    }

    return StatusWarning
}

func (s *Server) IsAvailable() bool {
    return s.GetStatus() != StatusUnhealthy
}
```

### 6.3 主动健康检查实现

```go
package active

import (
    "context"
    "net/http"
    "time"
    "health-checker/internal/server"
)

type Config struct {
    Interval time.Duration  // 检查间隔
    Timeout  time.Duration  // 超时时间
    Fails    int            // 失败阈值
    Passes   int            // 恢复阈值
    URI      string         // 健康检查路径
}

type Checker struct {
    servers []*server.Server
    config  Config
    client  *http.Client
}

func NewChecker(servers []*server.Server, config Config) *Checker {
    return &Checker{
        servers: servers,
        config:  config,
        client: &http.Client{
            Timeout: config.Timeout,
        },
    }
}

func (c *Checker) Start(ctx context.Context) {
    ticker := time.NewTicker(c.config.Interval)
    defer ticker.Stop()

    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            c.checkAll()
        }
    }
}

func (c *Checker) checkAll() {
    for _, srv := range c.servers {
        go c.checkOne(srv)
    }
}

func (c *Checker) checkOne(srv *server.Server) {
    url := srv.URL + c.config.URI

    resp, err := c.client.Get(url)
    if err != nil {
        c.handleFailure(srv)
        return
    }
    defer resp.Body.Close()

    if resp.StatusCode >= 200 && resp.StatusCode < 400 {
        c.handleSuccess(srv)
    } else {
        c.handleFailure(srv)
    }
}

func (c *Checker) handleSuccess(srv *server.Server) {
    srv.mu.Lock()
    defer srv.mu.Unlock()

    srv.ActiveFailCount = 0
    srv.ActiveSuccessCount++

    if srv.ActiveSuccessCount >= c.config.Passes {
        srv.ActiveHealthy = true
        srv.ActiveSuccessCount = 0
        log.Printf("[主动检查] %s 标记为健康", srv.URL)
    }
}

func (c *Checker) handleFailure(srv *server.Server) {
    srv.mu.Lock()
    defer srv.mu.Unlock()

    srv.ActiveSuccessCount = 0
    srv.ActiveFailCount++

    if srv.ActiveFailCount >= c.config.Fails {
        srv.ActiveHealthy = false
        srv.ActiveFailCount = 0
        log.Printf("[主动检查] %s 标记为不健康", srv.URL)
    }
}
```

### 6.4 被动健康检查实现

```go
package passive

import (
    "sync"
    "time"
    "health-checker/internal/server"
)

type Config struct {
    MaxFails    int
    FailTimeout time.Duration
}

type Monitor struct {
    servers []*server.Server
    config  Config
    mu      sync.RWMutex
}

func NewMonitor(servers []*server.Server, config Config) *Monitor {
    return &Monitor{
        servers: servers,
        config:  config,
    }
}

// 记录请求结果（由负载均衡器调用）
func (m *Monitor) RecordRequest(srv *server.Server, success bool) {
    srv.mu.Lock()
    defer srv.mu.Unlock()

    now := time.Now()

    // 如果超出时间窗口，重置计数器
    if now.Sub(srv.PassiveFailWindow) > m.config.FailTimeout {
        srv.PassiveFailCount = 0
        srv.PassiveFailWindow = now
    }

    if success {
        // 成功后重置
        srv.PassiveFailCount = 0
        srv.PassiveHealthy = true
    } else {
        // 失败累计
        srv.PassiveFailCount++

        if srv.PassiveFailCount >= m.config.MaxFails {
            srv.PassiveHealthy = false
            log.Printf("[被动检查] %s 标记为不健康", srv.URL)
        }
    }
}
```

### 6.5 组合策略实现

```go
package strategy

import (
    "health-checker/internal/server"
)

type CombinedStrategy struct {
    servers []*server.Server
}

func NewCombinedStrategy(servers []*server.Server) *CombinedStrategy {
    return &CombinedStrategy{servers: servers}
}

// 获取可用服务器列表
func (s *CombinedStrategy) GetAvailableServers() []*server.Server {
    var available []*server.Server

    for _, srv := range s.servers {
        status := srv.GetStatus()

        if status == server.StatusHealthy {
            // 健康：完整权重
            available = append(available, srv)
        } else if status == server.StatusWarning {
            // 警告：降低权重
            srvCopy := *srv
            srvCopy.Weight = srv.Weight / 2
            available = append(available, &srvCopy)
        }
        // 不健康：不加入列表
    }

    return available
}

// 统计健康状态
func (s *CombinedStrategy) GetStats() map[server.HealthStatus]int {
    stats := make(map[server.HealthStatus]int)

    for _, srv := range s.servers {
        status := srv.GetStatus()
        stats[status]++
    }

    return stats
}
```

### 6.6 完整示例

```go
package main

import (
    "context"
    "time"
    "health-checker/internal/server"
    "health-checker/pkg/active"
    "health-checker/pkg/passive"
    "health-checker/pkg/strategy"
)

func main() {
    // 初始化后端服务器
    servers := []*server.Server{
        {URL: "http://backend1.example.com", Weight: 5},
        {URL: "http://backend2.example.com", Weight: 3},
        {URL: "http://backend3.example.com", Weight: 2},
    }

    // 配置主动健康检查
    activeConfig := active.Config{
        Interval: 5 * time.Second,
        Timeout:  2 * time.Second,
        Fails:    3,
        Passes:   2,
        URI:      "/health",
    }

    activeChecker := active.NewChecker(servers, activeConfig)

    // 配置被动健康检查
    passiveConfig := passive.Config{
        MaxFails:    3,
        FailTimeout: 30 * time.Second,
    }

    passiveMonitor := passive.NewMonitor(servers, passiveConfig)

    // 组合策略
    combinedStrategy := strategy.NewCombinedStrategy(servers)

    // 启动主动检查
    ctx := context.Background()
    go activeChecker.Start(ctx)

    // 模拟负载均衡器转发请求
    go func() {
        for {
            availableServers := combinedStrategy.GetAvailableServers()
            if len(availableServers) == 0 {
                log.Println("没有可用服务器")
                time.Sleep(1 * time.Second)
                continue
            }

            // 选择服务器（这里简化为轮询）
            srv := availableServers[0]

            // 转发请求并记录结果
            success := forwardRequest(srv)
            passiveMonitor.RecordRequest(srv, success)

            time.Sleep(100 * time.Millisecond)
        }
    }()

    // 定期打印统计
    ticker := time.NewTicker(10 * time.Second)
    defer ticker.Stop()

    for range ticker.C {
        stats := combinedStrategy.GetStats()
        log.Printf("健康统计: Healthy=%d, Warning=%d, Unhealthy=%d",
            stats[server.StatusHealthy],
            stats[server.StatusWarning],
            stats[server.StatusUnhealthy])
    }
}
```

---

## 7. 生产环境最佳实践

### 7.1 参数调优建议

| 参数 | 推荐值 | 理由 |
|------|-------|------|
| **interval** | 3-5 秒 | 平衡检测速度和开销 |
| **timeout** | 1-3 秒 | 避免慢响应影响 |
| **fails** | 2-3 次 | 避免网络抖动误判 |
| **passes** | 2-3 次 | 确保服务器稳定后再接入 |
| **max_fails** | 3-5 次 | 容忍偶发失败 |
| **fail_timeout** | 30-60 秒 | 给服务器恢复时间 |

### 7.2 常见陷阱

#### 陷阱1：健康检查过于简单

**问题**：
```go
// ❌ 太简单，无法反映真实状态
func healthHandler(w http.ResponseWriter, r *http.Request) {
    w.WriteHeader(http.StatusOK)
}
```

**改进**：
```go
// ✅ 检查关键依赖
func healthHandler(w http.ResponseWriter, r *http.Request) {
    if err := db.Ping(); err != nil {
        http.Error(w, "DB down", http.StatusServiceUnavailable)
        return
    }
    // ... 检查其他依赖
    w.WriteHeader(http.StatusOK)
}
```

#### 陷阱2：健康检查过于复杂

**问题**：
```go
// ❌ 太复杂，影响性能
func healthHandler(w http.ResponseWriter, r *http.Request) {
    // 执行复杂的数据库查询
    result := db.Query("SELECT COUNT(*) FROM large_table")
    // 执行大量计算
    calculateComplexMetrics()

    w.WriteHeader(http.StatusOK)
}
```

**改进**：
```go
// ✅ 轻量级检查
func healthHandler(w http.ResponseWriter, r *http.Request) {
    // 只做连接检查，不做查询
    if err := db.Ping(); err != nil {
        http.Error(w, "DB down", http.StatusServiceUnavailable)
        return
    }
    w.WriteHeader(http.StatusOK)
}
```

#### 陷阱3：忽略慢启动

**问题**：服务器刚启动，缓存未预热，立即接收全部流量导致过载。

**改进**：使用慢启动（Slow Start）
```nginx
upstream backend {
    server backend1.example.com slow_start=30s;  # 30秒内逐渐增加流量
}
```

### 7.3 监控指标

生产环境应监控以下指标：

1. **健康服务器数量**
   ```
   healthy_servers_count
   warning_servers_count
   unhealthy_servers_count
   ```

2. **健康检查成功率**
   ```
   active_check_success_rate
   passive_check_success_rate
   ```

3. **故障检测延迟**
   ```
   时间间隔：服务器崩溃 → 被标记为不健康
   ```

4. **误判率**
   ```
   被错误标记为不健康的次数 / 总标记次数
   ```

### 7.4 故障演练

定期进行故障演练，验证健康检查是否生效：

#### 演练1：服务器宕机
```bash
# 手动停止一台服务器
systemctl stop app-server

# 观察：
# 1. 多久检测到故障？
# 2. 流量是否正确转移？
# 3. 有多少请求失败？
```

#### 演练2：网络分区
```bash
# 使用 iptables 模拟网络故障
iptables -A INPUT -s <load-balancer-ip> -j DROP

# 观察健康检查的表现
```

#### 演练3：慢响应
```bash
# 在服务器上注入延迟
tc qdisc add dev eth0 root netem delay 5000ms

# 观察超时检测
```

---

## 总结

### 核心要点

1. **健康检查的本质**：快速检测故障 + 自动隔离 + 自动恢复

2. **被动健康检查**：
   - 监控真实流量
   - 无额外开销
   - 检测延迟较高

3. **主动健康检查**：
   - 主动探测
   - 检测快速
   - 有额外开销

4. **组合策略最佳**：
   - 分级响应（健康/警告/不健康）
   - 降低误判率
   - 提高系统可用性

### 设计清单

设计健康检查时，问自己这些问题：

- [ ] 系统流量高还是低？（决定主动 vs 被动）
- [ ] 能容忍多少故障影响？（决定检测延迟）
- [ ] 误判的代价是什么？（决定阈值设置）
- [ ] 需要检查哪些依赖？（决定健康端点实现）
- [ ] 如何处理渐进式故障？（决定是否需要分级策略）

### 进一步学习

1. **阅读源码**：
   - Nginx: `ngx_http_upstream_module.c`
   - HAProxy: `src/check.c`

2. **实践项目**：
   - 为你的负载均衡器添加健康检查
   - 实现慢启动机制
   - 添加监控和告警

3. **深入主题**：
   - 服务网格（Service Mesh）中的健康检查
   - Kubernetes liveness/readiness probes
   - 分布式系统中的故障检测算法
