# Ch07 事务

## 单对象与多对象事务操作

### 核心问题：什么需要事务保证?

事务的原子性保证可以分为两个层面：
1. **单对象操作**：对单个数据项的操作
2. **多对象操作**：涉及多个数据项的操作

---

### 1. 单对象写入（Single-Object Writes）

#### 1.1 为什么单对象也需要原子性？

即使是单个对象的操作，也可能面临失败场景：

**场景示例**：
- 写入 20KB JSON 文档时，写了 10KB 后网络中断
- 更新磁盘上的数据时，电源故障
- 覆盖旧值时，部分写入了新值

**后果**：如果没有原子性保证，可能读到"半成品"数据（部分旧值 + 部分新值）

#### 1.2 数据库如何实现单对象原子性？

大多数存储引擎提供以下机制：

##### （1）原子性与隔离性
- **日志机制**（Write-Ahead Log, WAL）：
  - 先写日志，再修改数据
  - 崩溃恢复时可回滚未完成的写入

- **写时复制**（Copy-on-Write）：
  - B树等数据结构的常见做法
  - 写入新版本，不修改旧版本
  - 完成后原子性切换指针

##### （2）单对象的高级操作

许多数据库提供更复杂的单对象原子操作：

```sql
-- 原子递增（避免 read-modify-write 竞争）
UPDATE counters SET value = value + 1 WHERE key = 'page_views';
```

```python
# Redis 的原子操作
redis.incr('page_views')  # 原子递增
redis.getset('key', 'new_value')  # 原子获取并设置
```

**Compare-and-Set (CAS)**：
```python
# 只有当前值是 expected_value 时才更新
UPDATE users SET name = 'Alice'
WHERE id = 123 AND version = 5;  -- 乐观锁
```

#### 1.3 单对象操作的局限性

虽然提供原子性，但**不是真正的事务**：
- ❌ 不支持跨多个对象的原子性
- ❌ 不提供回滚机制（某些 NoSQL）
- ❌ 不保证跨操作的隔离性

---

### 2. 多对象事务（Multi-Object Transactions）

#### 2.1 为什么需要多对象事务？

**核心问题**：许多操作需要同时修改多个对象，且要么全部成功，要么全部失败。

#### 典型场景

##### 场景 1：维护外键约束
```sql
-- 插入订单明细时，必须保证订单存在
BEGIN TRANSACTION;
  INSERT INTO orders (id, user_id) VALUES (1001, 42);
  INSERT INTO order_items (order_id, product_id) VALUES (1001, 'SKU123');
COMMIT;
```

如果没有事务：
- `orders` 插入成功，`order_items` 失败 → 留下孤儿记录
- 或者 `order_items` 引用不存在的 `order_id` → 违反外键约束

##### 场景 2：非规范化数据的一致性
```json
// 用户文档（非规范化存储）
{
  "user_id": 42,
  "name": "Alice",
  "unread_count": 5  // 冗余字段
}

// 消息文档
{
  "msg_id": 101,
  "to_user": 42,
  "is_read": false
}
```

**更新操作**：用户读取消息时
```python
# 需要同时更新两个文档
BEGIN TRANSACTION
  UPDATE messages SET is_read = true WHERE msg_id = 101
  UPDATE users SET unread_count = unread_count - 1 WHERE user_id = 42
COMMIT
```

如果没有事务保证：
- 消息标记为已读，但 `unread_count` 未减少 → 数据不一致
- 并发操作可能导致计数错误

##### 场景 3：二级索引的更新
```sql
-- 更新用户邮箱
UPDATE users SET email = 'new@example.com' WHERE id = 42;
```

数据库内部需要：
1. 更新主表记录
2. 删除旧索引项 `old@example.com → user_id:42`
3. 插入新索引项 `new@example.com → user_id:42`

**如果索引更新失败**：
- 索引与数据不一致
- 查询 `SELECT * FROM users WHERE email = 'new@example.com'` 可能找不到记录

##### 场景 4：经典转账问题
```sql
BEGIN TRANSACTION;
  UPDATE accounts SET balance = balance - 100 WHERE account_id = 'A';
  UPDATE accounts SET balance = balance + 100 WHERE account_id = 'B';
COMMIT;
```

要求：
- 要么两个账户都更新成功
- 要么都不更新（保持原状）
- 不能出现钱"消失"或"凭空产生"

---

### 3. 处理错误和中止（Error Handling and Aborts）

#### 3.1 事务中止的语义

**ACID 数据库的承诺**：
- 如果事务中止（abort），所有写入都会被**回滚**（rolled back）
- 应用可以安全地**重试**（retry）

```python
# 典型的事务重试逻辑
max_retries = 3
for attempt in range(max_retries):
    try:
        with db.transaction():
            # 执行多个操作
            db.execute("UPDATE accounts SET balance = balance - 100 WHERE id = 'A'")
            db.execute("UPDATE accounts SET balance = balance + 100 WHERE id = 'B'")
        break  # 成功，退出重试
    except TransactionAbortError:
        if attempt == max_retries - 1:
            raise  # 最后一次重试失败，抛出异常
        time.sleep(0.1 * (2 ** attempt))  # 指数退避
```

#### 3.2 并非所有系统都支持中止

**无事务回滚的系统**（如部分 NoSQL）：
- Leaderless replication（如 Dynamo 风格的数据库）
- 应用层需要自己处理失败

```python
# 应用层需要手动清理
try:
    db.put('order:1001', order_data)
    db.put('order_items:1001', items_data)
except Exception:
    # 需要手动删除已写入的数据
    db.delete('order:1001')  # 补偿操作
    raise
```

#### 3.3 重试的陷阱

重试并非总是安全的：

##### （1）网络问题导致的重复提交
```
Client → [UPDATE balance...] → Database
        ← [网络超时，未收到响应]
Client → [重试 UPDATE balance...] → Database
```

可能结果：
- 第一次请求实际成功了，但客户端超时
- 重试导致扣款两次

**解决方案**：
- 使用**幂等性操作**（idempotent operations）
- 客户端生成唯一请求 ID，数据库去重

##### （2）重试风暴导致过载
- 系统过载时，大量客户端同时重试
- 进一步加剧过载 → 雪崩效应

**解决方案**：
- 指数退避（exponential backoff）
- 限流和熔断机制

##### （3）副作用已执行
```python
with db.transaction():
    db.execute("INSERT INTO orders ...")
    send_email_to_customer()  # 外部副作用
    # 如果此处失败，事务回滚但邮件已发送
```

**问题**：事务回滚不会撤销外部副作用（如发邮件、调用第三方 API）

**解决方案**：
- 将副作用移到事务外部
- 使用**两阶段提交**或**消息队列**确保最终一致性

---

### 4. 关键设计权衡

| 特性 | 单对象操作 | 多对象事务 |
|------|-----------|-----------|
| **实现复杂度** | 低（日志/COW） | 高（锁/MVCC/2PC） |
| **性能开销** | 低 | 较高（协调成本） |
| **适用场景** | 计数器、单记录更新 | 转账、订单系统 |
| **分布式支持** | 容易 | 困难（需分布式事务） |

#### 何时使用多对象事务？

**需要事务**：
- 金融系统（转账、支付）
- 订单系统（订单 + 库存 + 积分）
- 强一致性要求的场景

**可以不用事务**：
- 日志写入（追加操作）
- 分析数据（可容忍短暂不一致）
- 使用最终一致性的推荐系统

#### 替代方案

如果系统不支持事务，可以使用：
1. **应用层事务**：自己实现补偿逻辑（Saga 模式）
2. **最终一致性**：允许短暂不一致，后台异步修复
3. **冲突解决**：使用 CRDT（Conflict-free Replicated Data Types）

---

### 5. 实际案例对比

#### 案例 1：Redis（单对象原子性）

```python
# Redis 只保证单个命令的原子性
redis.incr('counter')  # ✅ 原子的

# 多个命令需要使用 Lua 脚本或 MULTI/EXEC
pipe = redis.pipeline()
pipe.decr('stock:item123')
pipe.incr('sales:item123')
pipe.execute()  # ⚠️ 非原子的（可能部分成功）

# 使用 MULTI/EXEC 实现事务
with redis.pipeline() as pipe:
    pipe.multi()
    pipe.decr('stock:item123')
    pipe.incr('sales:item123')
    pipe.execute()  # ✅ 原子执行
```

#### 案例 2：PostgreSQL（完整事务支持）

```sql
BEGIN;
  -- 扣减库存
  UPDATE inventory SET stock = stock - 1 WHERE product_id = 123 AND stock > 0;

  -- 如果库存不足，上面的 UPDATE 影响 0 行
  -- 检查并中止事务

  -- 创建订单
  INSERT INTO orders (user_id, product_id) VALUES (42, 123);

COMMIT;  -- 全部成功或全部失败
```

#### 案例 3：MongoDB（有限的事务支持）

```javascript
// MongoDB 4.0+ 支持多文档事务（需 replica set）
const session = client.startSession();
session.startTransaction();

try {
  await ordersCollection.insertOne({ order_id: 1001, user_id: 42 }, { session });
  await usersCollection.updateOne(
    { user_id: 42 },
    { $inc: { total_orders: 1 } },
    { session }
  );

  await session.commitTransaction();
} catch (error) {
  await session.abortTransaction();
  throw error;
} finally {
  session.endSession();
}
```

---

### 6. 核心要点总结

#### 单对象操作
✅ 大多数数据库提供单对象原子性（通过 WAL 或 COW）
✅ 支持原子递增、CAS 等高级操作
❌ 无法处理跨对象的一致性需求

#### 多对象事务
✅ 保证多个操作的原子性（全部成功或全部失败）
✅ 维护数据一致性（外键、索引、非规范化数据）
❌ 实现复杂，性能开销较高
❌ 分布式环境下更加困难

#### 设计建议
1. **优先使用单对象操作**：如果业务逻辑允许
2. **必要时使用事务**：涉及多个对象且必须保持一致性
3. **考虑最终一致性**：某些场景可以接受短暂不一致
4. **注意重试安全性**：实现幂等性，避免重复执行
5. **外部副作用需谨慎**：不要在事务内执行不可回滚的操作

---

## 弱隔离级别

只有出现某个事务修改数据而另一个事务同时要读取该数据，或者两个事务同时修改相同数据时，才会引发并发问题（引入了竞争条件）。

数据库一直试图通过事务隔离来对应用开发者隐藏内部的各种并发问题。可串行化的隔离会严重影响性能，而许多数据库却不愿意牺牲性能，因而更多倾向于**采用较弱的隔离级别**，它可以防止某些但并非全部的并发问题。

### 读-提交

读提交是最基本的的事务隔离级别，它只提供以下两个保证：
1. 读数据库肘，只能看到巳成功提交的数据（防止“脏读”）;
2. 写数据库肘，只会覆盖已成功提交的数据（防止“脏写”）。

#### 防止脏读

要求: **事务的任何写入只有在成功提交之后，才能被其他人观察到。**

当有以下需求时，需要防止脏读：
- 事务需要更新多个对象；
- 事务发生终止，则所有的写入操作都需要回滚；如果这时发生了脏读，则它可能会看到稍后会被回滚的数据。


#### 防止脏写

要求：**事务只能覆盖已经成功提交的数据，不能覆盖其他未提交事务的写入。**

##### 什么是脏写？

脏写（Dirty Write）是指一个事务覆盖了另一个**尚未提交**的事务所写入的数据。

##### 典型问题场景

**场景：汽车销售系统**

假设 Alice 和 Bob 同时购买同一辆车，两个事务并发执行：

```sql
-- Alice 的事务
BEGIN TRANSACTION;
  UPDATE listings SET buyer = 'Alice' WHERE car_id = 1;  -- T1 时刻
  -- ... 其他操作 ...
  UPDATE invoices SET buyer = 'Alice' WHERE car_id = 1;  -- T3 时刻
COMMIT;  -- T5 时刻

-- Bob 的事务（并发执行）
BEGIN TRANSACTION;
  UPDATE listings SET buyer = 'Bob' WHERE car_id = 1;    -- T2 时刻（覆盖 Alice 的未提交写入）
  -- ... 其他操作 ...
  UPDATE invoices SET buyer = 'Bob' WHERE car_id = 1;    -- T4 时刻
COMMIT;  -- T6 时刻
```

**如果允许脏写，可能的执行顺序**：
1. T1: Alice 更新 `listings.buyer = 'Alice'`（未提交）
2. T2: Bob 更新 `listings.buyer = 'Bob'`（覆盖了 Alice 的未提交写入）
3. T3: Alice 更新 `invoices.buyer = 'Alice'`
4. T4: Bob 更新 `invoices.buyer = 'Bob'`
5. T5: Alice 提交
6. T6: Bob 提交

**最终结果**：
- `listings.buyer = 'Bob'`（Bob 的写入）
- `invoices.buyer = 'Bob'`（Bob 的写入）
- 看似正常，但如果执行顺序稍有不同...

**更糟糕的情况**：
1. T1: Alice 更新 `listings.buyer = 'Alice'`
2. T2: Bob 更新 `listings.buyer = 'Bob'`（脏写）
3. T3: Alice 更新 `invoices.buyer = 'Alice'`
4. T5: Alice 提交
5. T4: Bob 更新 `invoices.buyer = 'Bob'`
6. T6: Bob 提交

**最终结果**：
- `listings.buyer = 'Bob'`
- `invoices.buyer = 'Bob'`

但如果 Bob 的事务在 Alice 提交后回滚：
- `listings.buyer = 'Alice'`（Alice 提交的）
- `invoices.buyer = 'Alice'`（Alice 提交的）

**数据不一致问题**：部分数据来自 Alice，部分来自 Bob！

##### 脏写导致的问题

1. **数据不一致**
   - 多个相关字段被不同事务部分覆盖
   - 违反了数据完整性约束

2. **回滚复杂性**
   ```
   事务A: 写入 X=1 (未提交)
   事务B: 写入 X=2 (覆盖了A的写入，未提交)
   事务A: 回滚

   问题：X 应该回滚到什么值？
   - 原始值？但 B 的写入会丢失
   - B 的值？但 A 需要回滚
   ```

3. **并发控制失效**
   - 无法保证事务的隔离性
   - 事务之间产生意外的相互影响

##### 如何防止脏写？

数据库通常使用**行级锁**（Row-level Lock）来防止脏写：

**实现机制**：
```
事务A: 获取 car_id=1 的写锁
事务A: UPDATE listings SET buyer = 'Alice' WHERE car_id = 1
事务B: 尝试获取 car_id=1 的写锁 → 阻塞等待
事务A: UPDATE invoices SET buyer = 'Alice' WHERE car_id = 1
事务A: COMMIT（释放锁）
事务B: 获取锁成功
事务B: UPDATE listings SET buyer = 'Bob' WHERE car_id = 1
事务B: COMMIT
```

**关键点**：
- 事务在修改某行数据时，必须先获取该行的**写锁**
- 如果另一个事务已持有该锁，当前事务必须**等待**
- 直到持有锁的事务**提交或回滚**后，锁才被释放
- 后续事务才能获取锁并修改数据

##### 读-提交的实现

大多数数据库通过以下方式实现读-提交：

**防止脏写**：
- 使用**行级锁**（Row-level Lock）
- 写操作时加锁，提交/回滚时释放

**防止脏读**：
- 方案1（简单但低效）：**读锁** - 读操作也加锁
  - 问题：一个长时间运行的写事务会阻塞所有读操作

- 方案2（常用）：**记住旧值** - 数据库保存每个对象的两个版本
  ```
  当事务A正在修改某行时：
  - 未提交的新值：只有事务A能看到
  - 已提交的旧值：其他事务读取时返回此值
  - 事务A提交后，新值成为"已提交的值"
  ```

##### 代码示例对比

**错误示例（允许脏写）**：
```python
# 模拟无锁并发修改
def transaction_alice():
    db.execute("UPDATE listings SET buyer = 'Alice' WHERE car_id = 1")
    time.sleep(1)  # 模拟其他操作
    db.execute("UPDATE invoices SET buyer = 'Alice' WHERE car_id = 1")
    db.commit()

def transaction_bob():
    time.sleep(0.5)
    db.execute("UPDATE listings SET buyer = 'Bob' WHERE car_id = 1")  # 脏写！
    db.execute("UPDATE invoices SET buyer = 'Bob' WHERE car_id = 1")
    db.commit()

# 并发执行
threading.Thread(target=transaction_alice).start()
threading.Thread(target=transaction_bob).start()
# 结果：数据不一致
```

**正确示例（防止脏写）**：
```python
# 数据库自动使用行锁
def transaction_alice():
    with db.transaction():  # BEGIN
        db.execute("UPDATE listings SET buyer = 'Alice' WHERE car_id = 1")
        # 此时 car_id=1 被锁定
        time.sleep(1)
        db.execute("UPDATE invoices SET buyer = 'Alice' WHERE car_id = 1")
    # COMMIT 后释放锁

def transaction_bob():
    time.sleep(0.5)
    with db.transaction():
        # 这里会等待 Alice 的事务完成
        db.execute("UPDATE listings SET buyer = 'Bob' WHERE car_id = 1")
        db.execute("UPDATE invoices SET buyer = 'Bob' WHERE car_id = 1")
    # COMMIT

# 并发执行 - 但数据库保证串行执行冲突的写入
threading.Thread(target=transaction_alice).start()
threading.Thread(target=transaction_bob).start()
# 结果：要么全是 Alice，要么全是 Bob（取决于谁先获取锁）
```

##### PostgreSQL 示例

```sql
-- Session 1 (Alice)
BEGIN;
UPDATE listings SET buyer = 'Alice' WHERE car_id = 1;
-- 获取了 car_id=1 的行锁
SELECT pg_sleep(5);  -- 模拟长时间操作

-- Session 2 (Bob) - 在 Session 1 提交前执行
BEGIN;
UPDATE listings SET buyer = 'Bob' WHERE car_id = 1;
-- 这里会阻塞，等待 Session 1 释放锁
-- 提示: waiting for lock...

-- Session 1 继续
UPDATE invoices SET buyer = 'Alice' WHERE car_id = 1;
COMMIT;  -- 释放锁

-- Session 2 此时获取到锁，继续执行
UPDATE invoices SET buyer = 'Bob' WHERE car_id = 1;
COMMIT;
```

##### 读-提交的局限性

虽然防止了脏读和脏写，但**读-提交级别仍然存在其他并发问题**：

1. **不可重复读**（Non-repeatable Read）
   ```sql
   -- 事务A
   BEGIN;
   SELECT balance FROM accounts WHERE id = 1;  -- 返回 100
   -- 此时事务B修改并提交 balance = 200
   SELECT balance FROM accounts WHERE id = 1;  -- 返回 200（不一致！）
   COMMIT;
   ```

2. **幻读**（Phantom Read）
   ```sql
   -- 事务A
   BEGIN;
   SELECT COUNT(*) FROM users WHERE age > 18;  -- 返回 10
   -- 此时事务B插入新用户并提交
   SELECT COUNT(*) FROM users WHERE age > 18;  -- 返回 11（出现"幻影"）
   COMMIT;
   ```

这些问题需要更强的隔离级别来解决（如快照隔离、可串行化隔离）。

##### 核心要点

✅ **读-提交保证**：
- 只读取已提交的数据（防止脏读）
- 只覆盖已提交的数据（防止脏写）

✅ **实现方式**：
- 脏写：行级锁
- 脏读：保存旧值版本

❌ **不解决的问题**：
- 不可重复读
- 幻读
- 写偏斜（Write Skew）
- 更新丢失（Lost Update）

🎯 **适用场景**：
- 大多数 OLTP 系统的默认隔离级别
- PostgreSQL、Oracle、SQL Server 的默认设置
- 性能与一致性的平衡选择


### 快照级别隔离与可重复读

#### 核心问题：为什么需要快照隔离？

读-提交隔离级别存在**不可重复读**问题，这在某些场景下会导致严重的业务错误。

##### 典型问题场景

**场景 1：备份数据库**

```sql
-- 备份进程（长时间运行）
BEGIN TRANSACTION;  -- 使用读-提交
SELECT * FROM accounts;     -- 读取账户表（假设需要 1 小时）
SELECT * FROM transactions; -- 读取交易表

-- 在备份过程中，用户 Alice 转账：
UPDATE accounts SET balance = balance - 100 WHERE user_id = 1;
UPDATE accounts SET balance = balance + 100 WHERE user_id = 2;
COMMIT;
```

**问题**：
- 如果备份进程在 Alice 转账的中间时刻读取数据
- 可能读到：账户 1 已扣款，但账户 2 还未加款
- **备份数据不一致**：总金额少了 100 元！

**场景 2：分析查询**

```sql
-- 分析师运行报表（耗时 30 分钟）
BEGIN TRANSACTION;
SELECT COUNT(*) FROM users WHERE status = 'active';     -- 返回 1000
-- ... 其他分析查询 ...
SELECT COUNT(*) FROM users WHERE status = 'active';     -- 返回 1005（有人注册了）
-- 同一个查询在同一个事务中返回不同结果！
```

**问题**：
- 分析结果不一致
- 无法保证报表的准确性
- 难以复现和调试问题

---

#### 快照隔离（Snapshot Isolation）

##### 核心思想

**每个事务都从数据库的一致性快照中读取数据**。

- 事务开始时，看到的是**该时刻的完整快照**
- 事务执行期间，即使其他事务修改并提交了数据，当前事务**看到的仍是快照版本**
- 每个事务看到的是数据库在某个特定时间点的状态

##### 快照隔离的保证

1. **一致性读取**（Consistent Read）
   - 事务中的每次读取都看到相同版本的数据
   - 解决了不可重复读问题

2. **时间点一致性**（Point-in-Time Consistency）
   - 读取的是事务开始时刻的数据快照
   - 不会看到部分提交的结果

3. **读操作不阻塞写操作**
   - 读取历史快照，不需要加锁
   - 写操作继续进行，不影响已开始的读事务

---

#### 实现机制：多版本并发控制（MVCC）

##### MVCC 基本原理

**Multi-Version Concurrency Control**：数据库维护一个对象的**多个版本**。

**核心数据结构**：
```sql
-- 每行数据包含多个版本
CREATE TABLE accounts (
    account_id INT,
    balance DECIMAL,
    created_by BIGINT,    -- 创建此版本的事务ID
    deleted_by BIGINT     -- 删除此版本的事务ID（NULL 表示未删除）
);

-- 示例数据（逻辑视图）
| account_id | balance | created_by | deleted_by |
|------------|---------|------------|------------|
| 42         | 1000    | TXN-10     | TXN-15     |  -- 旧版本
| 42         | 900     | TXN-15     | NULL       |  -- 当前版本
```

##### 事务 ID 分配

每个事务都有一个**单调递增的唯一 ID**：
```
TXN-10 < TXN-11 < TXN-12 < ...
```

##### 版本可见性规则

**事务 T 能看到某个版本的数据，当且仅当**：

1. **创建条件**：
   ```
   created_by <= T 的事务ID
   ```
   版本是在事务 T 开始之前或同时创建的

2. **未删除条件**：
   ```
   deleted_by IS NULL  OR  deleted_by > T 的事务ID
   ```
   版本在事务 T 开始时还未被删除

3. **创建者已提交**：
   ```
   created_by 对应的事务在 T 开始时已提交
   ```

4. **不能看到自己未提交的写入的情况**：
   - 某些实现中，事务可以看到自己的写入
   - 但不能看到其他未提交事务的写入

##### 详细示例

**场景**：多个事务并发读写账户余额

```sql
-- 初始状态
| account_id | balance | created_by | deleted_by |
|------------|---------|------------|------------|
| 42         | 1000    | TXN-1      | NULL       |

-- 时间线：
T1: TXN-10 开始（读事务，快照时刻 = 10）
T2: TXN-11 开始，修改余额为 900
    UPDATE accounts SET balance = 900 WHERE account_id = 42;
    实现步骤：
    1. 标记旧版本被删除：deleted_by = TXN-11
    2. 插入新版本：created_by = TXN-11

| account_id | balance | created_by | deleted_by |
|------------|---------|------------|------------|
| 42         | 1000    | TXN-1      | TXN-11     |  -- 旧版本（已删除）
| 42         | 900     | TXN-11     | NULL       |  -- 新版本

T3: TXN-11 提交
T4: TXN-10 读取余额
    SELECT balance FROM accounts WHERE account_id = 42;

    可见性判断：
    - 旧版本 (balance=1000):
      ✅ created_by (TXN-1) <= TXN-10
      ✅ deleted_by (TXN-11) > TXN-10
      → 可见！返回 1000

    - 新版本 (balance=900):
      ❌ created_by (TXN-11) > TXN-10
      → 不可见

T5: TXN-10 再次读取余额
    SELECT balance FROM accounts WHERE account_id = 42;
    → 仍然返回 1000（可重复读！）

T6: TXN-12 开始（新的读事务，快照时刻 = 12）
    SELECT balance FROM accounts WHERE account_id = 42;

    可见性判断：
    - 旧版本: deleted_by (TXN-11) <= TXN-12 → 不可见
    - 新版本: created_by (TXN-11) <= TXN-12 → 可见
    → 返回 900
```

---

#### 更新和删除的实现

##### UPDATE 操作

```sql
-- 应用层执行
UPDATE accounts SET balance = 900 WHERE account_id = 42;

-- 数据库内部实现（MVCC）
BEGIN;
  -- 1. 标记旧版本为已删除
  UPDATE accounts_internal
  SET deleted_by = current_txn_id()
  WHERE account_id = 42 AND deleted_by IS NULL;

  -- 2. 插入新版本
  INSERT INTO accounts_internal (account_id, balance, created_by, deleted_by)
  VALUES (42, 900, current_txn_id(), NULL);
COMMIT;
```

##### DELETE 操作

```sql
-- 应用层执行
DELETE FROM accounts WHERE account_id = 42;

-- 数据库内部实现
UPDATE accounts_internal
SET deleted_by = current_txn_id()
WHERE account_id = 42 AND deleted_by IS NULL;

-- 注意：物理删除延后进行（垃圾回收）
```

---

#### 索引与 MVCC

##### 问题：索引如何处理多版本？

**方案 1：索引指向所有版本**

```
B-Tree 索引：
account_id=42 → [版本1(TXN-1), 版本2(TXN-11), 版本3(TXN-15)]

读取时：
1. 通过索引找到所有版本
2. 应用可见性规则，过滤出当前事务可见的版本
```

**优点**：实现简单
**缺点**：垃圾版本也占用索引空间

**方案 2：Append-Only B-Tree**

PostgreSQL 使用的方案：
```
每个索引项包含版本信息：
(account_id=42, TXN-1)  → 行位置1
(account_id=42, TXN-11) → 行位置2
```

---

#### 垃圾回收（Garbage Collection）

##### 为什么需要垃圾回收？

随着事务的执行，旧版本数据会不断积累：
```
| account_id | balance | created_by | deleted_by |
|------------|---------|------------|------------|
| 42         | 1000    | TXN-1      | TXN-11     |  ← 没有事务能看到
| 42         | 900     | TXN-11     | TXN-15     |  ← 没有事务能看到
| 42         | 800     | TXN-15     | TXN-20     |  ← 没有事务能看到
| 42         | 700     | TXN-20     | NULL       |  ← 当前版本
```

##### 垃圾回收策略

**何时可以删除旧版本？**

当所有可能需要该版本的事务都已结束时：
```
可删除条件：
deleted_by < 所有活跃事务的最小事务ID
```

**PostgreSQL 的 VACUUM 机制**：

```sql
-- 手动触发垃圾回收
VACUUM accounts;

-- 自动 VACUUM（后台进程）
-- postgresql.conf:
autovacuum = on
autovacuum_naptime = 1min  -- 每分钟检查一次
```

**垃圾回收过程**：
1. 扫描表，找到所有已删除的旧版本
2. 检查是否有活跃事务还需要这些版本
3. 如果没有，物理删除这些版本
4. 更新索引，移除指向已删除版本的条目

---

#### 快照隔离的写冲突

##### 问题：两个事务同时写入

虽然快照隔离解决了读问题，但**写-写冲突**仍然存在：

**场景：两个用户同时修改文档**

```sql
-- 初始状态：doc_id=1, content='Hello', version=1

-- 事务 A（快照时刻 = 10）
BEGIN TRANSACTION ISOLATION LEVEL REPEATABLE READ;
SELECT content FROM docs WHERE id = 1;  -- 读到 'Hello'
-- 用户编辑...
UPDATE docs SET content = 'Hello World', version = 2 WHERE id = 1 AND version = 1;

-- 事务 B（快照时刻 = 10，同时进行）
BEGIN TRANSACTION ISOLATION LEVEL REPEATABLE READ;
SELECT content FROM docs WHERE id = 1;  -- 也读到 'Hello'
-- 用户编辑...
UPDATE docs SET content = 'Hello Alice', version = 2 WHERE id = 1 AND version = 1;
```

**问题**：后提交的事务会覆盖先提交的事务的修改！

##### 解决方案：First-Committer-Wins

大多数数据库实现的策略：

```sql
-- 事务 A 先提交
BEGIN;
UPDATE docs SET content = 'Hello World' WHERE id = 1;
COMMIT;  ✅ 成功

-- 事务 B 后提交
BEGIN;
UPDATE docs SET content = 'Hello Alice' WHERE id = 1;
COMMIT;  ❌ 失败！ERROR: could not serialize access due to concurrent update

-- 应用层需要处理冲突
try:
    with db.transaction(isolation='repeatable-read'):
        # ... 修改数据 ...
        db.commit()
except SerializationError:
    # 重试或提示用户冲突
    handle_conflict()
```

**实现机制**：
- 事务提交时，检查是否有其他事务修改了相同的行
- 如果有冲突，后提交的事务被中止（abort）
- 应用层需要处理冲突并重试

---

#### 可重复读（Repeatable Read）

##### 术语混淆

**可重复读**是 SQL 标准定义的隔离级别，但不同数据库的实现不同：

| 数据库 | REPEATABLE READ 实现 |
|--------|---------------------|
| **PostgreSQL** | 快照隔离（Snapshot Isolation） |
| **MySQL (InnoDB)** | 快照隔离 |
| **Oracle** | 不支持此级别，使用 SERIALIZABLE 或 READ COMMITTED |
| **SQL Server** | 快照隔离（需显式启用 `SET TRANSACTION ISOLATION LEVEL SNAPSHOT`） |

##### SQL 标准定义

SQL 标准要求 REPEATABLE READ 防止：
- ✅ 脏读（Dirty Read）
- ✅ 不可重复读（Non-repeatable Read）
- ⚠️ 幻读（Phantom Read）- 标准允许，但某些数据库也防止了

---

#### 代码示例

##### PostgreSQL 快照隔离

```sql
-- 会话 1
BEGIN TRANSACTION ISOLATION LEVEL REPEATABLE READ;
SELECT balance FROM accounts WHERE id = 1;  -- 返回 500

-- 会话 2（并发）
BEGIN;
UPDATE accounts SET balance = 600 WHERE id = 1;
COMMIT;

-- 会话 1 继续
SELECT balance FROM accounts WHERE id = 1;  -- 仍返回 500（快照！）
UPDATE accounts SET balance = balance - 100 WHERE id = 1;
COMMIT;  -- 可能失败（写冲突）
```

##### Python 应用代码

```python
import psycopg2
from psycopg2.extensions import ISOLATION_LEVEL_REPEATABLE_READ

def process_order_with_snapshot(order_id):
    conn = psycopg2.connect(database="mydb")
    conn.set_isolation_level(ISOLATION_LEVEL_REPEATABLE_READ)

    max_retries = 3
    for attempt in range(max_retries):
        try:
            with conn.cursor() as cur:
                # 读取订单信息（快照）
                cur.execute("SELECT * FROM orders WHERE id = %s", (order_id,))
                order = cur.fetchone()

                # 处理业务逻辑
                total_price = calculate_price(order)

                # 更新订单
                cur.execute(
                    "UPDATE orders SET total = %s WHERE id = %s",
                    (total_price, order_id)
                )

                conn.commit()
                break  # 成功

        except psycopg2.extensions.TransactionRollbackError:
            # 并发冲突，重试
            conn.rollback()
            if attempt == max_retries - 1:
                raise  # 最后一次重试失败
            time.sleep(0.1 * (2 ** attempt))  # 指数退避

    conn.close()
```

---

#### 快照隔离的优缺点

##### 优点

✅ **解决读异常**：
- 防止脏读
- 防止不可重复读
- 某些实现也防止幻读

✅ **性能优异**：
- 读操作不阻塞写操作
- 写操作不阻塞读操作
- 适合读多写少的场景

✅ **一致性视图**：
- 长时间分析查询得到一致结果
- 备份数据保证时间点一致性

##### 缺点

❌ **写冲突处理**：
- 需要应用层处理冲突重试
- 高竞争场景下重试频繁

❌ **存储开销**：
- 需要保存多个版本
- 垃圾回收增加系统负担

❌ **仍存在异常**：
- 写偏斜（Write Skew）
- 幻读（某些实现）
- 更新丢失（Lost Update）

---

#### 核心要点总结

**快照隔离（Snapshot Isolation）**：
- 每个事务看到数据库的一致性快照
- 通过 MVCC 实现多版本并发控制
- 读操作不加锁，性能优异

**可重复读（Repeatable Read）**：
- SQL 标准定义的隔离级别
- 大多数现代数据库通过快照隔离实现
- 不同数据库实现细节有差异

**实现机制**：
- 每行数据维护多个版本
- 事务 ID 标记版本创建和删除
- 可见性规则决定事务看到哪个版本
- 垃圾回收清理旧版本

**适用场景**：
- 数据分析和报表（长时间读取）
- 数据库备份
- 读多写少的 OLTP 系统
- 需要可重复读保证的业务

-------

### 防止更新丢失

#### 核心问题：更新丢失（Lost Update）

**更新丢失**是指两个事务执行"读-修改-写"（Read-Modify-Write）序列时，其中一个事务的写入覆盖了另一个事务的写入，导致数据丢失。

##### 典型的读-修改-写模式

```
1. 读取当前值
2. 基于当前值计算新值
3. 写入新值
```

如果两个事务并发执行这个序列，可能会发生更新丢失。

---

#### 典型场景

##### 场景 1：计数器递增

```sql
-- 初始值：counter = 5

-- 事务 A
BEGIN;
SELECT counter FROM counters WHERE id = 1;  -- 读到 5
-- 应用层计算：new_value = 5 + 1 = 6
UPDATE counters SET counter = 6 WHERE id = 1;
COMMIT;

-- 事务 B（并发执行）
BEGIN;
SELECT counter FROM counters WHERE id = 1;  -- 也读到 5
-- 应用层计算：new_value = 5 + 1 = 6
UPDATE counters SET counter = 6 WHERE id = 1;
COMMIT;

-- 最终结果：counter = 6（期望是 7！）
-- 一次递增丢失了
```

##### 场景 2：购物车更新

```python
# 用户 Alice 和 Bob 同时修改购物车
# 初始状态：cart = {'item1': 2, 'item2': 3}

# Alice 添加 item3
cart = db.get('cart:user123')  # 读
cart['item3'] = 1              # 修改
db.set('cart:user123', cart)   # 写

# Bob 更新 item1 数量（同时进行）
cart = db.get('cart:user123')  # 读（也读到初始状态）
cart['item1'] = 5              # 修改
db.set('cart:user123', cart)   # 写（覆盖了 Alice 的修改）

# 最终结果：{'item1': 5, 'item2': 3}
# Alice 添加的 item3 丢失了！
```

##### 场景 3：维基百科编辑冲突

```
时间线：
T1: Alice 读取文章内容（版本 1）
T2: Bob 读取文章内容（版本 1）
T3: Alice 编辑并保存（版本 2）
T4: Bob 编辑并保存（版本 3）

结果：Bob 的保存覆盖了 Alice 的修改
```

##### 场景 4：银行账户余额

```sql
-- 账户余额：balance = 1000

-- 事务 A：存款 500
BEGIN;
SELECT balance FROM accounts WHERE id = 42;  -- 读到 1000
-- new_balance = 1000 + 500 = 1500
UPDATE accounts SET balance = 1500 WHERE id = 42;
COMMIT;

-- 事务 B：取款 200（并发）
BEGIN;
SELECT balance FROM accounts WHERE id = 42;  -- 也读到 1000
-- new_balance = 1000 - 200 = 800
UPDATE accounts SET balance = 800 WHERE id = 42;
COMMIT;

-- 最终结果：balance = 800 或 1500（取决于谁后提交）
-- 期望结果：1000 + 500 - 200 = 1300
```

---

#### 解决方案

##### 方案 1：原子写操作

**最简单的解决方案**：使用数据库提供的原子操作，避免在应用层实现读-修改-写。

**SQL 原子更新**：

```sql
-- ❌ 错误：应用层读-修改-写
SELECT counter FROM counters WHERE id = 1;  -- 读到 5
UPDATE counters SET counter = 6 WHERE id = 1;

-- ✅ 正确：原子递增
UPDATE counters SET counter = counter + 1 WHERE id = 1;
```

**其他原子操作示例**：

```sql
-- 原子递减
UPDATE inventory SET stock = stock - 1 WHERE product_id = 123;

-- 原子字符串拼接（PostgreSQL）
UPDATE documents SET content = content || ' new text' WHERE id = 1;

-- 原子数组追加（PostgreSQL）
UPDATE users SET tags = array_append(tags, 'new_tag') WHERE id = 42;
```

**Redis 原子操作**：

```python
# ✅ 原子递增
redis.incr('page_views')

# ✅ 原子递减
redis.decr('stock:item123')

# ✅ 原子加法
redis.incrby('score:user42', 100)

# ✅ 原子位操作
redis.setbit('online_users', user_id, 1)
```

**适用场景**：
- 简单的数值计数
- 字符串/数组追加
- 集合操作

**局限性**：
- 无法表达复杂的业务逻辑
- 不支持跨多个对象的原子更新

---

##### 方案 2：显式加锁（Explicit Locking）

**核心思想**：事务在读取对象时显式加锁，阻止其他事务并发修改。

**FOR UPDATE 锁**：

```sql
-- 事务 A
BEGIN;
SELECT balance FROM accounts WHERE id = 42 FOR UPDATE;
-- 此行被锁定，其他事务无法修改
-- 计算新余额
UPDATE accounts SET balance = new_balance WHERE id = 42;
COMMIT;  -- 释放锁

-- 事务 B（并发）
BEGIN;
SELECT balance FROM accounts WHERE id = 42 FOR UPDATE;
-- 这里会阻塞，等待事务 A 释放锁
```

**完整示例**：

```sql
-- 购物车更新（PostgreSQL）
BEGIN;
  -- 锁定购物车记录
  SELECT cart_data FROM shopping_carts
  WHERE user_id = 123 FOR UPDATE;

  -- 应用层修改
  -- cart_data['item3'] = 1

  -- 更新购物车
  UPDATE shopping_carts
  SET cart_data = new_cart_data
  WHERE user_id = 123;
COMMIT;
```

**Python 应用代码**：

```python
def add_item_to_cart(user_id, item_id, quantity):
    with db.transaction():
        # 锁定购物车
        cursor.execute(
            "SELECT cart_data FROM shopping_carts WHERE user_id = %s FOR UPDATE",
            (user_id,)
        )
        cart = cursor.fetchone()['cart_data']

        # 修改购物车
        cart[item_id] = cart.get(item_id, 0) + quantity

        # 写回数据库
        cursor.execute(
            "UPDATE shopping_carts SET cart_data = %s WHERE user_id = %s",
            (json.dumps(cart), user_id)
        )
```

**优点**：
- 简单直接，容易理解
- 适用于复杂的业务逻辑
- 保证强一致性

**缺点**：
- 性能开销（锁等待）
- 可能导致死锁
- 不适合高并发场景

**死锁示例**：

```sql
-- 事务 A
BEGIN;
SELECT * FROM accounts WHERE id = 1 FOR UPDATE;  -- 锁定账户 1
SELECT * FROM accounts WHERE id = 2 FOR UPDATE;  -- 等待账户 2

-- 事务 B
BEGIN;
SELECT * FROM accounts WHERE id = 2 FOR UPDATE;  -- 锁定账户 2
SELECT * FROM accounts WHERE id = 1 FOR UPDATE;  -- 等待账户 1

-- 死锁！两个事务互相等待
```

---

##### 方案 3：自动检测更新丢失

**核心思想**：数据库自动检测并发的读-修改-写序列，如果检测到更新丢失，则中止事务。

**实现方式**：

某些数据库（如 PostgreSQL 的 REPEATABLE READ 隔离级别）会自动检测：

```sql
-- 事务 A
BEGIN TRANSACTION ISOLATION LEVEL REPEATABLE READ;
SELECT balance FROM accounts WHERE id = 42;  -- 读到 1000
UPDATE accounts SET balance = 1500 WHERE id = 42;
COMMIT;  ✅ 成功

-- 事务 B（并发）
BEGIN TRANSACTION ISOLATION LEVEL REPEATABLE READ;
SELECT balance FROM accounts WHERE id = 42;  -- 也读到 1000
UPDATE accounts SET balance = 800 WHERE id = 42;
COMMIT;  ❌ 失败！ERROR: could not serialize access due to concurrent update
```

**应用层处理**：

```python
max_retries = 3
for attempt in range(max_retries):
    try:
        with db.transaction(isolation='repeatable-read'):
            balance = db.query("SELECT balance FROM accounts WHERE id = %s", (account_id,))
            new_balance = balance + amount
            db.execute("UPDATE accounts SET balance = %s WHERE id = %s", (new_balance, account_id))
        break  # 成功
    except SerializationError:
        if attempt == max_retries - 1:
            raise
        time.sleep(0.1 * (2 ** attempt))  # 指数退避
```

**支持的数据库**：
- ✅ PostgreSQL（REPEATABLE READ 及以上）
- ✅ MySQL InnoDB（REPEATABLE READ）
- ✅ SQL Server（SNAPSHOT ISOLATION）
- ❌ Oracle（不自动检测）
- ❌ MongoDB（不自动检测）

**优点**：
- 自动检测，无需手动加锁
- 性能优于显式加锁（读不阻塞）

**缺点**：
- 需要应用层处理冲突重试
- 不是所有数据库都支持

---

##### 方案 4：Compare-and-Set (CAS)

**核心思想**：更新时检查值是否被修改，只有值未变时才更新。

**乐观锁实现**：

```sql
-- 表结构包含版本号
CREATE TABLE documents (
    id INT PRIMARY KEY,
    content TEXT,
    version INT NOT NULL
);

-- 初始状态：version = 1

-- 事务 A
BEGIN;
SELECT content, version FROM documents WHERE id = 1;  -- 读到 version=1
-- 修改内容...
UPDATE documents
SET content = new_content, version = 2
WHERE id = 1 AND version = 1;  -- ✅ 成功（影响 1 行）
COMMIT;

-- 事务 B（并发）
BEGIN;
SELECT content, version FROM documents WHERE id = 1;  -- 读到 version=1
-- 修改内容...
UPDATE documents
SET content = another_content, version = 2
WHERE id = 1 AND version = 1;  -- ❌ 失败（影响 0 行，因为版本已变）
-- 检测到冲突
ROLLBACK;
```

**Python 实现**：

```python
def update_document_with_cas(doc_id, new_content):
    max_retries = 3
    for attempt in range(max_retries):
        # 读取当前版本
        result = db.query(
            "SELECT content, version FROM documents WHERE id = %s",
            (doc_id,)
        )
        current_version = result['version']

        # 修改内容
        modified_content = modify(result['content'], new_content)

        # CAS 更新
        affected_rows = db.execute(
            """UPDATE documents
               SET content = %s, version = %s
               WHERE id = %s AND version = %s""",
            (modified_content, current_version + 1, doc_id, current_version)
        )

        if affected_rows == 1:
            return True  # 成功

        # 冲突，重试
        if attempt == max_retries - 1:
            raise ConflictError("Update conflict after retries")
        time.sleep(0.1 * (2 ** attempt))

    return False
```

**使用时间戳的 CAS**：

```sql
CREATE TABLE documents (
    id INT PRIMARY KEY,
    content TEXT,
    last_modified TIMESTAMP NOT NULL
);

-- 更新时检查时间戳
UPDATE documents
SET content = new_content, last_modified = NOW()
WHERE id = 1 AND last_modified = expected_timestamp;
```

**Redis 的 WATCH/MULTI/EXEC**：

```python
def transfer_with_watch(redis_client, from_key, to_key, amount):
    with redis_client.pipeline() as pipe:
        max_retries = 3
        for attempt in range(max_retries):
            try:
                # 监视键
                pipe.watch(from_key, to_key)

                # 读取当前值
                from_balance = int(pipe.get(from_key) or 0)
                to_balance = int(pipe.get(to_key) or 0)

                # 检查余额
                if from_balance < amount:
                    raise InsufficientFunds()

                # 开始事务
                pipe.multi()
                pipe.set(from_key, from_balance - amount)
                pipe.set(to_key, to_balance + amount)
                pipe.execute()

                return True  # 成功
            except WatchError:
                # 键被修改，重试
                if attempt == max_retries - 1:
                    raise
                time.sleep(0.01)
```

**优点**：
- 乐观并发控制，性能好
- 适合冲突较少的场景
- 实现简单，跨数据库兼容

**缺点**：
- 需要额外的版本字段
- 冲突时需要重试
- 高竞争场景下重试频繁

---

##### 方案 5：冲突解决与合并

**核心思想**：允许并发更新，通过应用层逻辑合并冲突。

**场景：协作编辑**

```python
# 文档结构
document = {
    'id': 1,
    'content': 'Hello World',
    'version_vector': {'alice': 5, 'bob': 3}  # 向量时钟
}

# Alice 的修改
alice_version = {'alice': 6, 'bob': 3}
alice_content = 'Hello Beautiful World'

# Bob 的修改（并发）
bob_version = {'alice': 5, 'bob': 4}
bob_content = 'Hello World!!!'

# 冲突检测：版本向量不可比较
# 解决方案：三路合并（Three-Way Merge）
base_content = 'Hello World'
merged_content = three_way_merge(base_content, alice_content, bob_content)
# 结果：'Hello Beautiful World!!!'

merged_version = {'alice': 6, 'bob': 4}
```

**购物车冲突合并**：

```python
def merge_shopping_carts(base_cart, cart_a, cart_b):
    """合并两个并发修改的购物车"""
    merged = {}

    # 合并所有商品
    all_items = set(base_cart.keys()) | set(cart_a.keys()) | set(cart_b.keys())

    for item in all_items:
        base_qty = base_cart.get(item, 0)
        qty_a = cart_a.get(item, 0)
        qty_b = cart_b.get(item, 0)

        # 计算变化量
        delta_a = qty_a - base_qty
        delta_b = qty_b - base_qty

        # 合并变化
        merged_qty = base_qty + delta_a + delta_b

        if merged_qty > 0:
            merged[item] = merged_qty

    return merged

# 示例
base_cart = {'item1': 2, 'item2': 3}
cart_a = {'item1': 2, 'item2': 3, 'item3': 1}  # Alice 添加 item3
cart_b = {'item1': 5, 'item2': 3}              # Bob 修改 item1

merged = merge_shopping_carts(base_cart, cart_a, cart_b)
# 结果：{'item1': 5, 'item2': 3, 'item3': 1}
```

**CRDT（Conflict-free Replicated Data Types）**：

```python
# 使用 CRDT 的计数器
class GCounter:
    """只增计数器（Grow-only Counter）"""
    def __init__(self):
        self.counts = {}  # {replica_id: count}

    def increment(self, replica_id):
        self.counts[replica_id] = self.counts.get(replica_id, 0) + 1

    def value(self):
        return sum(self.counts.values())

    def merge(self, other):
        """合并两个副本（自动解决冲突）"""
        merged = GCounter()
        all_replicas = set(self.counts.keys()) | set(other.counts.keys())
        for replica_id in all_replicas:
            merged.counts[replica_id] = max(
                self.counts.get(replica_id, 0),
                other.counts.get(replica_id, 0)
            )
        return merged

# 使用示例
counter_a = GCounter()
counter_a.increment('replica1')  # 1
counter_a.increment('replica1')  # 2

counter_b = GCounter()
counter_b.increment('replica2')  # 1

# 并发修改后合并
merged = counter_a.merge(counter_b)
print(merged.value())  # 3（无冲突）
```

**适用场景**：
- 协作编辑（Google Docs）
- 分布式系统（最终一致性）
- 离线优先应用

**优点**：
- 允许高并发修改
- 无需锁或阻塞
- 支持离线操作

**缺点**：
- 实现复杂
- 需要领域特定的合并逻辑
- 可能需要人工干预解决冲突

---

#### 各方案对比

| 方案 | 性能 | 复杂度 | 适用场景 | 数据库支持 |
|------|------|--------|----------|-----------|
| **原子写操作** | ⭐⭐⭐⭐⭐ | ⭐ | 简单计数、追加 | 大部分数据库 |
| **显式加锁** | ⭐⭐ | ⭐⭐ | 复杂业务逻辑 | 所有 SQL 数据库 |
| **自动检测** | ⭐⭐⭐⭐ | ⭐⭐⭐ | 通用场景 | PostgreSQL, MySQL |
| **CAS** | ⭐⭐⭐⭐ | ⭐⭐ | 冲突较少场景 | 所有数据库 |
| **冲突合并** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | 协作编辑、分布式 | 需应用层实现 |

---

#### 实际案例

##### 案例 1：Twitter 点赞计数

```python
# ❌ 错误：读-修改-写
likes = redis.get(f'tweet:{tweet_id}:likes')
redis.set(f'tweet:{tweet_id}:likes', likes + 1)

# ✅ 正确：原子递增
redis.incr(f'tweet:{tweet_id}:likes')
```

##### 案例 2：库存扣减

```sql
-- ❌ 错误：读-修改-写
BEGIN;
SELECT stock FROM inventory WHERE product_id = 123;  -- 读到 10
-- 检查库存充足...
UPDATE inventory SET stock = 9 WHERE product_id = 123;
COMMIT;

-- ✅ 正确：原子扣减 + 约束检查
UPDATE inventory
SET stock = stock - 1
WHERE product_id = 123 AND stock >= 1;
-- 检查 affected_rows，如果为 0 则库存不足
```

##### 案例 3：Notion 协作编辑

**使用 Operational Transformation (OT)**：

```python
# 操作类型
class Operation:
    INSERT = 'insert'
    DELETE = 'delete'

# 两个并发操作
op_a = {'type': 'insert', 'pos': 5, 'char': 'X'}
op_b = {'type': 'delete', 'pos': 3}

# 转换操作（确保一致性）
def transform(op1, op2):
    if op1['type'] == 'insert' and op2['type'] == 'delete':
        if op1['pos'] > op2['pos']:
            op1['pos'] -= 1  # 调整插入位置
    return op1, op2
```

---

#### 核心要点总结

**更新丢失（Lost Update）**：
- 读-修改-写序列的并发问题
- 导致一个事务的修改被另一个覆盖
- 读-提交和快照隔离都无法防止

**解决方案选择**：
1. **优先使用原子操作**（最简单、最快）
2. **CAS 适合冲突少的场景**（乐观锁）
3. **显式加锁适合复杂逻辑**（悲观锁）
4. **自动检测需要数据库支持**（REPEATABLE READ）
5. **冲突合并适合协作场景**（CRDT、OT）

**设计建议**：
- 优先在数据库层面解决（原子操作、约束）
- 避免应用层读-修改-写模式
- 使用版本号实现乐观锁
- 高并发场景考虑 CRDT
- 复杂业务逻辑使用显式锁

**下一节预告**：
- 写偏斜（Write Skew）
- 幻读（Phantom Read）
- 可串行化隔离（Serializable Isolation）


